# ndp
Reading club Neuro-Dynamic Programming by Bertsekas & Tsitsiklis

We will orchestrate a reading club based on the book Neuro-Dynamic Programming by Bertsekas & Tsitsiklis. The goal is to provide a focus for getting this book read and understood.

![Neuro-Dynamic Programming](http://athenasc.com/ndpcover.gif)

See the [book web](http://athenasc.com/ndpbook.html) site for the table of contents and **pointers to related literature**

You will need to be truly committed, as you are expected to:

- read the forthcoming chapter(s) every two weeks -- ???
- present one chapter yourself
    - slides? 
    - **productive reading** discuss worked solutions to OpenAI requests for research as we move along -- [openai.md](/openai.md)

If you are interested in taking part, please send an email to [team@dropoutlabs.com](mailto:team@dropoutlabs.com) or fork+PR :-)

## Premliminary Schedule

|                                                       |        |
|-------------------------------------------------------|--------|
| Appendix A: Mathematical Review                       | 17/06? |
| Introduction                                          |        |
| Dynamic Programming                                   |        |
| Neural Network Architectures and Training             |        |
| Stochastic Iterative Algorithms                       |        |
| Simulation Methods for a Lookup Table Representation  |        |
| Approximate DP with Cost-to-Go Function Approximation |        |
| Extensions                                            |        |
| Case Studies                                          |        |


## Products of the Reading Club

TBD

## Currently Registered Members

- Yakov Z 

## References
* DEEP REINFORCEMENT LEARNING: AN OVERVIEW (https://arxiv.org/pdf/1701.07274.pdf)

We give an overview of recent exciting achievements of deep reinforcement learning
(RL). We start with background of deep learning and reinforcement learning,
as well as introduction of testbeds. Next we discuss Deep Q-Network (DQN) and
its extensions, asynchronous methods, policy optimization, reward, and planning.
After that, we talk about attention and memory, unsupervised learning, and learning
to learn. Then we discuss various applications of RL, including games, in
particular, AlphaGo, robotics, spoken dialogue systems (a.k.a. chatbot), machine
translation, text sequence prediction, neural architecture design, personalized web
services, healthcare, finance, and music generation. We mention topics/papers not
reviewed yet. After listing a collection of RL resources, we close with discussions.

* Reinforcement Learning: An Introduction (http://ufal.mff.cuni.cz/~straka/courses/npfl114/2016/sutton-bookdraft2016sep.pdf)

The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.
